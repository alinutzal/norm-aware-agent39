# configs/base.yaml

project:
  name: nora-pipeline
  version: "0.1.0"

run:
  id: ${now:%Y-%m-%d_%H-%M-%S}
  out_dir: runs/${run.id}__${model.name}__${dataset.name}__seed${seed}
  tags: []

seed: 42
device: cuda
dtype: fp16        # fp32 | fp16 | bf16

dataset:
  name: cifar10
  root: data
  raw_dir: ${dataset.root}/raw
  processed_dir: ${dataset.root}/processed
  num_workers: 8
  pin_memory: true
  persistent_workers: true

  # Augmentation policy (train-only by default; violations can override)
  train_augment:
    random_crop: true
    crop_padding: 4
    hflip: true
  eval_augment:
    random_crop: false
    hflip: false

  # Normalization: computed once on TRAIN split and stored under processed_dir
  normalize:
    use_train_stats: true
    stats_file: ${dataset.processed_dir}/${dataset.name}/train_stats.json

model:
  name: deit_tiny
  num_classes: 10
  pretrained: false

train:
  epochs: 50
  batch_size: 256
  grad_clip_norm: 1.0
  log_every_steps: 50
  eval_every_epochs: 1

optimizer:
  name: adamw
  lr: 3e-4
  weight_decay: 0.05
  betas: [0.9, 0.999]
  eps: 1e-8

scheduler:
  name: cosine
  warmup_epochs: 5

amp:
  enabled: true
  grad_scaler: true
  detect_anomaly: false
  loss_nan_policy: halt     # halt | warn | ignore

repro:
  deterministic: false
  cudnn_benchmark: true
  cudnn_deterministic: false
  set_float32_matmul_precision: high   # highest | high | medium (torch>=2)
  dataloader_seed_workers: true

checkpoint:
  save_best: true
  save_last: true
  save_every_epochs: 1
  include_optimizer: true
  include_scheduler: true
  include_scaler: true

metrics:
  primary: top1_acc
  report_mean_std: true
  report_conf_int: false
  confidence_level: 0.95

reporting:
  require_multi_seed: true
  required_fields:
    - dataset_hash
    - split_hash
    - config_hash
    - git_commit
    - env
    - hardware
    - seeds

wandb:
  enabled: false  # Set to true to enable Weights & Biases logging
  project: norm-aware-ml
